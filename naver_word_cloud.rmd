---
title: "try_this_9th_of April"
output: html_document
author: 백영래
---
#1. 네이버 뉴스 1면의 기사들을 수집하시오.
#(https://news.naver.com/main/home.nhn)

```{r }
library(rvest); library(httr); library(stringr); library(dplyr)
library(rJava)
library(KoNLP)
library(RColorBrewer)
library(wordcloud)
library(arules); library(igraph); library(combinat)
library(arulesViz); library(visNetwork)


newsUrl = "https://news.naver.com/main/ranking/popularDay.nhn?mid=etc&sid1=111"
newsUrl
html = read_html(newsUrl)
html
links = html_attr(html_nodes(html, '.content dt a'), 'href')
links = links[!is.na(links)]
length(links)
head(links)
news = list()
for (i in 1:length(links)) {
  try({
    htxt = read_html(paste0('https://news.naver.com', links[i]))
    comments = html_nodes(htxt, '#articleBodyContents')
    get_news = repair_encoding(html_text(comments))   # repair_encoding(html_text(comments), from='utf-8')
    news[i] = str_trim(get_news)
  }, silent = F)
}
news[[28]][1]
length(news)

removeStopword = function(t) {
  t = gsub("[[:cntrl:]]", "", t) 
  t = gsub("http[s]?://[[:alnum:].\\/]+", "", t) 
  t = gsub("&[[:alnum:]]+;", "", t)
  t = gsub("@[[:alnum:]]+", "", t)
  t = gsub("@[[:alnum:]]+[:]?", "", t)
  t = gsub("[ㄱ-ㅎㅏ-ㅣ]","",t) 
  t = gsub("\\s{2,}", " ", t) 
  t = gsub("[[:punct:]]", "", t)  
  t = gsub("https", "", t)
  t = gsub("RT", "", t)
  t = gsub("\\s{2,}", " ", t) 
  t = gsub('[[:alnum:]]+@[[:alnum:].]+', '', t)  # email 제거
  # mac: emo 제거s
  #gsub('\\p{So}|\\p{Cn}', '', t, perl = TRUE)
}

removeStopword(news)
for (i in 1:length(news)) {
  news[[i]][1] = removeStopword(news[[i]][1])
  news[[i]][1] = gsub("flash 오류를 우회하기 위한 함수 추가function flashremoveCallback", "", news[[i]][1])
}

news



news[[28]][1]
news[[28]][1] = gsub("[[:cntrl:]]", "", news[[28]][1]) 


#news[[28]][1] = NULL

news
```

#2. 수집 된 뉴스로 WordCloud를 작도하시오.



```{r }

Sys.setenv(JAVA_HOME="C:/Program Files/Java/jre1.8.0_201/")



# 1. 명사 추출
# nouns = sapply(news, extractNoun, USE.NAMES = F)
wc = sapply(news, extractNoun, USE.NAMES = F)
wc1 = table(unlist(wc))
names(wc1)
length(wc1)
# 2. 상위 n 개 추출
wc2 = head(sort(wc1, decreasing = T), 100)
wc2

# 3. wordcloud

pal = brewer.pal(9, "Set1")
wordcloud(names(wc2), freq=wc2, scale=c(5,0.5), rot.per=0.25, 
            min.freq = 1, random.order = F, random.color = T, colors = pal)

```

#3. 수집 된 뉴스로 연관성분석을 하시오.



```{r }
#install.packages(c("arules", "igraph", "combinat", "arulesViz", "visNetwork"))
library(KoNLP)

nouns = sapply(wc, unique)
nouns1 = sapply(nouns, function(x) {
  Filter(function(y='') { nchar(y) <= 4 && nchar(y) > 1  }, x)
})
nouns1
wtrans = as(nouns1, "transactions")
rules = apriori(wtrans, parameter = list(supp=0.15, conf=0.5))
inspect(sort(rules))


# lift 기준으로 상위 20개만을 시각화
subrules2 <- head(sort(rules, by="lift"), 20)
ig <- plot( subrules2, method="graph", control=list(type="items") )
```

